{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person re-identification using Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Why Siamese Network ?</b>\n",
    "\n",
    "A Siamese Network is a type of neural network architecture that is used for tasks that involve finding similarities or differences between two input samples. \n",
    "\n",
    "The network is trained to output a high value when the two input samples are similar and a low value when they are dissimilar. This makes it useful for a variety of applications, such as image or text similarity matching, face recognition, and signature verification.\n",
    "\n",
    "One of main advantages of a Siamese Network is that it can be trained with very few examples, making it useful for applications where data is limited. Additionally, the shared weights between the two subnetworks allow the model to generalize well to new inputs.\n",
    "\n",
    "We will see the applications for re-identification of images in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About Dataset \n",
    "\n",
    "Dataset consists of Anchor image. positive image that is closer to the anchor image, and negative image which is farther apart. \n",
    "\n",
    "Each of the row will pass through siamese neural net for example resnet, and will output embeddings. These are then passed to a triplet loss function, and we learn the feature representation.  The reqiuired output will be postvbe amd anchor images near to each other and negative should be far apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
    "!pip install --upgrade opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"/Users/dhwaninijhawan/Documents/Portfolio/DeepLearning/siamese.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('/content/Person-Re-Id-Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/dhwaninijhawan/Documents/Portfolio/DeepLearning/Person-Re-Id-Dataset/train'\n",
    "csv_file = '/Users/dhwaninijhawan/Documents/Portfolio/DeepLearning/Person-Re-Id-Dataset/train.csv'\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Person-Re-Id-Dataset'...\n",
      "remote: Enumerating objects: 12942, done.\u001b[K\n",
      "remote: Counting objects: 100% (12942/12942), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12942/12942), done.\u001b[Kjects:  87% (11260/12942)\u001b[K\n",
      "remote: Total 12942 (delta 0), reused 12942 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (12942/12942), 27.68 MiB | 3.79 MiB/s, done.\n",
      "Updating files: 100% (12939/12939), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/parth1620/Person-Re-Id-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anchor</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420_c5s3_052165_01.jpg</td>\n",
       "      <td>1334_c6s3_061492_05.jpg</td>\n",
       "      <td>1420_c3s3_051678_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420_c3s3_061978_03.jpg</td>\n",
       "      <td>0234_c3s3_079494_02.jpg</td>\n",
       "      <td>1420_c6s3_085567_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1420_c5s3_062565_05.jpg</td>\n",
       "      <td>0475_c2s1_122816_08.jpg</td>\n",
       "      <td>1420_c3s3_051653_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1420_c6s3_085592_04.jpg</td>\n",
       "      <td>0662_c2s2_036662_05.jpg</td>\n",
       "      <td>1420_c1s6_013446_04.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0663_c5s3_085987_03.jpg</td>\n",
       "      <td>1463_c2s3_098102_02.jpg</td>\n",
       "      <td>0663_c3s3_085544_06.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Anchor                 Negative                 Positive\n",
       "0  1420_c5s3_052165_01.jpg  1334_c6s3_061492_05.jpg  1420_c3s3_051678_01.jpg\n",
       "1  1420_c3s3_061978_03.jpg  0234_c3s3_079494_02.jpg  1420_c6s3_085567_02.jpg\n",
       "2  1420_c5s3_062565_05.jpg  0475_c2s1_122816_08.jpg  1420_c3s3_051653_01.jpg\n",
       "3  1420_c6s3_085592_04.jpg  0662_c2s2_036662_05.jpg  1420_c1s6_013446_04.jpg\n",
       "4  0663_c5s3_085987_03.jpg  1463_c2s3_098102_02.jpg  0663_c3s3_085544_06.jpg"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f48b03cdc3e5d0b14ef1c9ac6eb59f8b8f380de588baf562fdd62896c75b9f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
